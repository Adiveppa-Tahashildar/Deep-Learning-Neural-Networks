{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d6fb32fd69316596e236eab5fb8cf77c848508c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f674695f1742479cefdeec0e81ab469f7b6ec90f"
   },
   "source": [
    "### Load the data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "aca2f1d9da3f35d104763166fe4d25448410d8f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',delimiter=',',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53083ccecf39523cff290495a6cc768061ba9b46"
   },
   "source": [
    "Drop the columns that are not required for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "95a8b5d6f19cf42d4f55c6d2842faf1d0d55c1d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "v1    5572 non-null object\n",
      "v2    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c7060084470000f39a2dcc15b656586dcd6e9fd"
   },
   "source": [
    "Understand the distribution better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a12002f521dd8eaeb0f69a932cbf23815ffd09d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.v1)\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "353a8191f86c3a22843a729b5d4a5acefbf94be8"
   },
   "source": [
    "* Create input and output vectors.\n",
    "* Process the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoder:\n",
    "Encode labels with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a1a345c1683e2fcc7173ecae867a5da87f2dde24"
   },
   "outputs": [],
   "source": [
    "X = df.v2\n",
    "Y = df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "150e244a39b814d8a41bbe0e419bc5f28e457dd6"
   },
   "source": [
    "Split into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "aa3386af09469682c66cc53a1830a4e42f0e70b6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5378d55c271e01480c1ac07f94ff99a80f900d6"
   },
   "source": [
    "### Process the data\n",
    "* Tokenize the data and convert the text to sequences.\n",
    "* Add padding to ensure that all the sequences have the same shape.\n",
    "* There are many ways of taking the *max_len* and here an arbitrary length of 150 is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Keras Text Tokenizer\n",
    "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...\n",
    "\n",
    "##### 2. texts_to_sequences: \n",
    "Transform each text in texts in a sequence of integers. \n",
    "\n",
    "##### 3. Keras Pad Sequences:\n",
    "Pads sequences to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bdca14f2b8cd7bd7cb5ee66fd40ea522217c03c6"
   },
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad8706caa7a447fb49b44919fd109129e4082a93"
   },
   "source": [
    "### RNN\n",
    "Define the RNN structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN is a recurrent neural network. It is a type of deep learning model. Unlike feed-forward neural networks, recurrent neural networks have a backward connection between hidden layers. Therefore, they have some kind of memory in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Keras Embedding Layer \n",
    "Keras offers an Embedding layer that can be used for neural networks on text data. It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras.\n",
    "\n",
    "##### 2. LSTM\n",
    "Long Short Term Memory networks, usually called “LSTMs” , were introduced by Hochreiter and Schmiduber. These have widely been used for speech recognition, language modeling, sentiment analysis and text prediction.\n",
    "\n",
    "LSTM has a special architecture which enables it to forget the unnecessary information .\n",
    "\n",
    "##### 3. ReLU activation function\n",
    "\n",
    "ReLU (rectified linear unit) is one of the most popular function which is used as hidden layer activation function in deep neural network. ReLU activation function is defined as. g ( z ) = max { 0 , z }.\n",
    "\n",
    "##### 4. Dropout\n",
    "Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.\n",
    "\n",
    "The effect is that the network becomes less sensitive to the specific weights of neurons. This in turn results in a network that is capable of better generalization and is less likely to overfit the training data.\n",
    "\n",
    "##### 5. Sigmoid Activation Function\n",
    "A sigmoid function is a mathematical function having a characteristic \"S\"-shaped curve or sigmoid curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "78fff25b8be1de575bff071a2027f3dd2b11b911"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d7c489e32bff6d12b8c08c07a91e9ba5d302e0e"
   },
   "source": [
    "Call the function and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a0ede32d4127e8b4990fd74fe97fadef9e565d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc2e0a3ec50d14c790b82d66f9255456ec6a69da"
   },
   "source": [
    "Fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "98f6d6318352420ea49c532cda158f715f940f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TanushPasupuleti\\Anaconda3\\envs\\tanush_data_science\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 11s 3ms/step - loss: 0.3471 - accuracy: 0.8598 - val_loss: 0.1512 - val_accuracy: 0.9409\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 10s 3ms/step - loss: 0.0972 - accuracy: 0.9747 - val_loss: 0.0555 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 10s 3ms/step - loss: 0.0466 - accuracy: 0.9863 - val_loss: 0.0631 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ad458c898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "448ab38c2f804e47df48eb45385393aaec168032"
   },
   "source": [
    "The model performs well on the validation set and this configuration is chosen as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccca7839445a7d663ee7bc425a16e247df3e0e5b"
   },
   "source": [
    "Process the test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "80036135a11387d952becaf2fecf653a65c02328"
   },
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b60d7d2bcc0aabf77c8c8766c59f8d73cd34547"
   },
   "source": [
    "Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0db183049b59d96388812a98efedfc865b7cc141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 1s 901us/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "3e121ab83f4a0b9f7376ab24aa25d67051171f89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.046\n",
      "  Accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfd9d4cfc125942ea07adcd55da75b996465c2ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9064bae0e16602fbbaa652140173e32bd1c04840"
   },
   "source": [
    "source for attention: [https://github.com/philipperemy/keras-attention-mechanism/blob/master/attention_lstm.py](http://)\n",
    "source for other code: [https://www.kaggle.com/kredy10/simple-lstm-for-text-classification/notebook](http://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention\n",
    "Attention is a mechanism combined in the RNN allowing it to focus on certain parts of the input sequence when predicting a certain part of the output sequence, enabling easier learning and of higher quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9cada4b5e83fc646b6dacd96ab67dc3b8e6f1d05"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "4e5287b50dfb6bde299617766d1f7ac52e1c5ae2"
   },
   "outputs": [],
   "source": [
    "SINGLE_ATTENTION_VECTOR = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    # output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    output_attention_mul = multiply([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "877dac6c5b8d2ea732109a9f20ae74cf50b96fab"
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_after_lstm():\n",
    "    #inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    \n",
    "    lstm_units = 64\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(layer)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "7a7166deb080cb4834d874bff9fcda8fba7be5fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers import multiply\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "ed17fe8472484cf65b88edd0251c2a29841131a9"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 50\n",
    "TIME_STEPS = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "b730b78aa48156b586cbec3f56e08663514d6872"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4736, 150), (4736, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "ce87ec6400c6ffc4f0133040b80243f96cdaab39"
   },
   "outputs": [],
   "source": [
    "m = model_attention_applied_after_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "c6110d70ac05da2e102a78cf077bbf86599995d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 150, 50)      50000       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 150, 64)      29440       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 64, 150)      0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64, 150)      0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 150)      22650       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 150, 64)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 150, 64)      0           lstm_3[0][0]                     \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9600)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            9601        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 111,691\n",
      "Trainable params: 111,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "916ddc97e1142214e685e12ff638d4a8f953690e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "72a29d2aaada65d13128593b1dfa207aa913ec98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 15s 4ms/step - loss: 0.5775 - accuracy: 0.8379 - val_loss: 0.4028 - val_accuracy: 0.8639\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.3981 - accuracy: 0.8651 - val_loss: 0.3977 - val_accuracy: 0.8639\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 13s 4ms/step - loss: 0.3924 - accuracy: 0.8651 - val_loss: 0.3876 - val_accuracy: 0.8639\n",
      "Epoch 4/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.3732 - accuracy: 0.8651 - val_loss: 0.3552 - val_accuracy: 0.8639\n",
      "Epoch 5/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.3293 - accuracy: 0.8651 - val_loss: 0.2953 - val_accuracy: 0.8639\n",
      "Epoch 6/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.2542 - accuracy: 0.8886 - val_loss: 0.2033 - val_accuracy: 0.9378\n",
      "Epoch 7/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.2026 - accuracy: 0.9427 - val_loss: 0.1828 - val_accuracy: 0.9546\n",
      "Epoch 8/10\n",
      "3788/3788 [==============================] - 13s 3ms/step - loss: 0.1814 - accuracy: 0.9504 - val_loss: 0.1690 - val_accuracy: 0.9578\n",
      "Epoch 9/10\n",
      "3788/3788 [==============================] - 14s 4ms/step - loss: 0.1401 - accuracy: 0.9625 - val_loss: 0.1209 - val_accuracy: 0.9631\n",
      "Epoch 10/10\n",
      "3788/3788 [==============================] - 14s 4ms/step - loss: 0.1074 - accuracy: 0.9678 - val_loss: 0.1088 - val_accuracy: 0.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ad8f7a978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "m.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "c3da604ff769e9178f1b9e47e431ef799af38454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 1s 1ms/step\n",
      "Test set\n",
      "  Loss: 0.091\n",
      "  Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "accr = m.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
