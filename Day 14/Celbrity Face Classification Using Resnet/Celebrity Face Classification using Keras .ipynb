{"cells":[{"metadata":{"_uuid":"adb037df26d8a7d6b8500b6ac5ffc3add0cd3cca"},"cell_type":"markdown","source":"This sample demonstrates celebrity face classification using Keras with transfer learning"},{"metadata":{"trusted":true,"_uuid":"3be06c09bd16cc29a775672cba60360e93f90409","collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/keras-pretrained-models/\"))\n\ndata_dir = '../input/5-celebrity-faces-dataset/data'\nvgg16weight = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet50weight = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c048e92155dbdf3ac117465021bcb12b511a1f8","scrolled":false,"collapsed":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import RMSprop, SGD\nfrom keras import backend as K\n\nimport keras\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"85628d9635634229bd8712d9a986415385d48bb6"},"cell_type":"markdown","source":"### 1. Prepare Data"},{"metadata":{"trusted":true,"_uuid":"aa0c9ecd43c4828b2a714948d3478c67383a9bda","collapsed":true},"cell_type":"code","source":"img_width, img_height = 200, 200\n\ntrain_data_dir = os.path.join(data_dir, 'train')\nvalidation_data_dir = os.path.join(data_dir, 'val')\nnb_train_samples = 93\nnb_validation_samples = 25\nepochs = 50\nbatch_size = 16\nnumclasses = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9f680ed21e84ed9cbbb4464a2ad4ff2cdc98f5b","scrolled":true,"collapsed":true},"cell_type":"code","source":"# dataset\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    #shear_range=0.2,\n    vertical_flip=False,\n    horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b6005e3cf37b715831e5112e2f69e4e8f40d4c3d"},"cell_type":"markdown","source":"### 2. Model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d40ddf608386f6c1d2d4b1af4e0a6614e76d0a75"},"cell_type":"code","source":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53895b45df5d332dc364b3d9b0b058d28889de52","collapsed":true},"cell_type":"code","source":"def vgg16CNNtl(input_shape, outclass, sigma='sigmoid'):\n    \n    base_model = None\n    base_model = keras.applications.VGG16(weights=None, include_top=False, input_shape=input_shape)\n    base_model.load_weights(vgg16weight)\n        \n    top_model = Sequential()\n    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    for i in range(2):\n        top_model.add(Dense(4096, activation='relu'))\n        top_model.add(Dropout(0.5))\n    top_model.add(Dense(outclass, activation=sigma))\n\n    model = None\n    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n    \n    return model\n \ndef resnet50tl(input_shape, outclass, sigma='sigmoid'):\n    \n    base_model = None\n    base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n    base_model.load_weights(resnet50weight)\n    \n    top_model = Sequential()\n    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    for i in range(2):\n        top_model.add(Dense(4096, activation='relu'))\n        top_model.add(Dropout(0.5))\n    top_model.add(Dense(outclass, activation=sigma))\n\n    model = None\n    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2434d17467a68ab77b8230cef39afc09e63f15c","collapsed":true},"cell_type":"code","source":"model = resnet50tl(input_shape, numclasses, 'softmax')\nlr = 1e-5\ndecay = 1e-7 #0.0\noptimizer = RMSprop(lr=lr, decay=decay)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dd22fe68f3571da784c2e71cc40999b25d0b319a"},"cell_type":"markdown","source":"### 3. Train"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"eb679a663f86cfcd737ef9413c469826c5f72a15","collapsed":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d0b0f3e58ae0b0901b09353d3f1b0a9db15a598","collapsed":true},"cell_type":"code","source":"# Get training and test loss histories\ntraining_loss = history.history['loss']\ntraining_acc = history.history['acc']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\nfig=plt.figure(figsize=(12, 4))\n# Visualize loss history\nfig.add_subplot(121)\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, training_acc, 'b-')\nplt.legend(['Training Loss', 'Training Accuracy'])\nplt.xlabel('Epoch')\nplt.ylabel('Training Loss/Acc')\n\n# Get training and test loss histories\nval_acc = history.history['val_acc']\ntraining_acc = history.history['acc']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(val_acc) + 1)\n\n# Visualize loss history\nfig.add_subplot(122)\nplt.plot(epoch_count, val_acc, 'r--')\nplt.plot(epoch_count, training_acc, 'b-')\nplt.legend(['Validation Accuracy', 'Training Accuracy'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8f3d0837aed7284b7024c38f77137bbe82ad8c2f"},"cell_type":"code","source":"saveweight =  'celebriytag_weight.h5'\nmodel.save_weights(saveweight)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"374258d36b7b06bb4a0201b87e8f82e219ccb24b"},"cell_type":"markdown","source":"### 4. Evaluation"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ec07fed520e584354e32b5f38a27a99ce83b43be"},"cell_type":"code","source":"from keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom io import BytesIO\nimport cv2\nimport requests\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32fa9768fc8b66a9607e8e7bc406d2bd18b7b150","scrolled":true,"collapsed":true},"cell_type":"code","source":"labels = ['ben_afflek',  'elton_john',  'jerry_seinfeld',  'madonna',  'mindy_kaling']\ntest_imgs = ['ben_afflek/httpabsolumentgratuitfreefrimagesbenaffleckjpg.jpg']\n\nfor test in test_imgs:\n    test_img = os.path.join(validation_data_dir, test)\n    img = image.load_img(test_img, target_size=(img_width, img_height))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x /= 255.\n    classes = model.predict(x)\n    result = np.squeeze(classes)\n    result_indices = np.argmax(result)\n    \n    img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.axis('off')\n    plt.title(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))\n    plt.imshow(img)\n    \n    #print(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}